# ============================================================================
# Databricks Local Emulator - Environment Configuration
# ============================================================================
# Copy this file to .env and customize the values for your environment
#
# For LOCAL MODE (notebooks without Docker):
#   - Leave these variables unset or commented out
#   - The emulator will run in pure local mode
#
# For DOCKER MODE (full environment with S3 + Hive metastore):
#   - Uncomment and configure the variables below
#   - Run: docker compose up -d --build
# ============================================================================

# ----------------------------------------------------------------------------
# MinIO (S3-compatible object storage)
# ----------------------------------------------------------------------------
# These credentials are used by PySpark to connect to MinIO
# Default credentials for MinIO (change for production!)

AWS_ACCESS_KEY_ID=minioadmin
AWS_SECRET_ACCESS_KEY=minioadmin
AWS_ENDPOINT_URL=http://minio:9000
AWS_REGION=us-east-1

# MinIO Console (Web UI)
# Access at: http://localhost:9001
# MINIO_ROOT_USER=minioadmin
# MINIO_ROOT_PASSWORD=minioadmin

# ----------------------------------------------------------------------------
# PostgreSQL (Hive Metastore backend)
# ----------------------------------------------------------------------------
# Database for storing Hive table metadata
# Only used in Docker mode

POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=metastore_db
POSTGRES_USER=hive
POSTGRES_PASSWORD=hive_password

# ----------------------------------------------------------------------------
# Spark Configuration (Optional)
# ----------------------------------------------------------------------------
# Uncomment to customize Spark settings

# SPARK_DRIVER_MEMORY=2g
# SPARK_EXECUTOR_MEMORY=2g
# SPARK_EXECUTOR_CORES=2

# ----------------------------------------------------------------------------
# Application Settings (Optional)
# ----------------------------------------------------------------------------
# Environment identifier

# APP_ENV=local
# APP_ENV=docker
# APP_ENV=production

# ----------------------------------------------------------------------------
# Databricks Workspace Simulation (Optional)
# ----------------------------------------------------------------------------
# Simulate Databricks workspace settings

# DATABRICKS_WORKSPACE_URL=https://my-workspace.cloud.databricks.com
# DATABRICKS_WORKSPACE_ID=1234567890
# DATABRICKS_CLUSTER_ID=local-cluster

# ----------------------------------------------------------------------------
# Logging (Optional)
# ----------------------------------------------------------------------------
# Control log verbosity

# LOG_LEVEL=INFO
# SPARK_LOG_LEVEL=WARN
# PYSPARK_LOG_LEVEL=WARN

# ----------------------------------------------------------------------------
# Notes
# ----------------------------------------------------------------------------
# 1. Never commit .env to version control (already in .gitignore)
# 2. MinIO default credentials are for development only
# 3. Change all passwords for production use
# 4. For local notebook development, comment out AWS_* and POSTGRES_* vars
# 5. For Docker mode, ensure docker-compose.yml uses these same values
